{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f48d0c4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## It's coding time again!\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"Images/Lecture-3/programming_skills.png\" width=\"1800\" alt='programming_skills'/>\n",
    "</div>\n",
    "</center>\n",
    "\n",
    "<br/>\n",
    "<br/>\n",
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47fad4a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Let's recall your interests\n",
    "\n",
    "61.8% is interested in programming mistakes!\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"Images/Lecture-1/google_form_true.png\" width=\"2200\" alt='google_form_true'/>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e770bcf",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Let's focus on this topic!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a981a9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Why do we need this lecture?\n",
    "\n",
    "Whether you like it or not, experimental setting might require you to do some coding stuff.\n",
    "\n",
    "Coding translates to: \n",
    "\n",
    "1. Transparency (*don't you dare do some cheap tricks!*)\n",
    "2. Correctness (*your code should reflect your paper statements*) \n",
    "3. **Readability** (*please, don't make this a nightmare*)\n",
    "4. Efficiency (*time is money*)\n",
    "5. **Maintainability** (*I'm sure you'll re-use this code*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bda74f6",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "In the past lecture, we have shown some tools to make our code more efficient in Tensorflow and Pytorch [4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc969f07",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "We now provide some tips & tricks concerning [3, 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9ee19f6",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## What are we going to cover?\n",
    "\n",
    "- Debugging\n",
    "- General coding best practices\n",
    "- Tensorflow and PyTorch best practices\n",
    "- Misc: code documentation and READMEs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9afc8f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "*The 5-minute-in-the-future of yourself and your friends will appreciate!*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14b02b9",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Debugging\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"Images/Lecture-4/programming_meme.png\" width=\"800\"/>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebb46f01",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What are we going to see\n",
    "\n",
    "- Using a debugger\n",
    "- Type hints, annotations, typechecking\n",
    "- Logging\n",
    "- Assertions and Unit tests\n",
    "- Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6aaebbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The debugging slice\n",
    "\n",
    "Whether you've already realized it or you still have to, debugging usually takes **around 90%** of your work time\n",
    "\n",
    "- 9% the idea\n",
    "- 1% code writing\n",
    "- 90% debugging\n",
    "\n",
    "It is tiresome, boring, stressful, annoying $\\rightarrow$ **we all know that!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5441e29a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### My point\n",
    "\n",
    "- We **don't really need** to be <u>good</u> programmers to write correct code (*what do you with mean with 'good'?*)\n",
    "- This lecture is **not** a computer science 101 course about programming (*I'm far from being competent on this matter*)\n",
    "- What I want to say is that you should learn **how to think** to tackle debugging"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6484209",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Debugging is like an investigation game where you have to find the culprit, and usually the culprit is you!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e2a21",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What are our weapons?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdce8be4",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "- [**Dynamic**] Debugger\n",
    "- [**Static**] Type hints\n",
    "- [**Dynamic**] Typechecking\n",
    "- [**Dynamic**] Assertions\n",
    "- [**Static**] Logging\n",
    "- [**Dynamic**] Unit tests\n",
    "- [**Dynamic**] Profiling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2e72a7",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "All these methods, **combined**, allow us to better inspect our code to find unwanted behaviours/features (*bugs*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fde2fbde",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using a Debugger\n",
    "\n",
    "Long story short, we have a powerful tool to inspect our code\n",
    "\n",
    "- Stop using ```print(...)``` for debugging\n",
    "- Just use a debugger\n",
    "- Just use a debugger\n",
    "- Just use a debugger\n",
    "- Got it?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7553a5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "There are **many powerful IDEs** that support a debugger: PyCharm, Spider, VisualStudio Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8566a2e8",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Unless you are a skilled programmer, just avoid programming with \n",
    "   - text editors like vim, sublimetext, nano, notepad++, etc.\n",
    "   - notebooks (*unless you need to run real experiments, not all of us are rich and have personal GPUs*)\n",
    "\n",
    "$\\rightarrow$ *personal opinion*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a161c1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What if we can't use an IDE (e.g., working on a remote server without GUI)?\n",
    "\n",
    "Python has a neat functionality that allows to run the Python Debugger [```pdb```](https://docs.python.org/3/library/pdb.html#debugger-commands) from command line\n",
    "\n",
    "$\\rightarrow$ just run your python script with ```python -i myscript.py``` for interactive mode and\n",
    "\n",
    "```\n",
    "    import pdb\n",
    "    pdb.pm()   # <-- run post-mortem debugger\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb6cf3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# crashing_app.py\n",
    "SOME_VAR = 42\n",
    "\n",
    "class SomeError(Exception):\n",
    "    pass\n",
    "\n",
    "def func():\n",
    "    raise SomeError(\"Something went wrong...\")\n",
    "\n",
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ba4fc5d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!python3 -i crashing_app.py\n",
    "\n",
    "Traceback (most recent call last):\n",
    "  File \"crashing_app.py\", line 9, in <module>\n",
    "    func()\n",
    "  File \"crashing_app.py\", line 7, in func\n",
    "    raise SomeError(\"Something went wrong...\")\n",
    "__main__.SomeError: Something went wrong...\n",
    ">>> # We are interactive shell\n",
    ">>> import pdb\n",
    ">>> pdb.pm()  # start Post-Mortem debugger\n",
    "> .../crashing_app.py(7)func()\n",
    "-> raise SomeError(\"Something went wrong...\")\n",
    "(Pdb) # Now we are in debugger and can poke around and run some commands:\n",
    "(Pdb) p SOME_VAR  # Print value of variable\n",
    "42\n",
    "(Pdb) l  # List surrounding code we are working with\n",
    "  2\n",
    "  3  \tclass SomeError(Exception):\n",
    "  4  \t    pass\n",
    "  5\n",
    "  6  \tdef func():\n",
    "  7  ->\t    raise SomeError(\"Something went wrong...\")\n",
    "  8\n",
    "  9  \tfunc()\n",
    "[EOF]\n",
    "(Pdb)  # Continue debugging... set breakpoints, step through the code, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ffbb8",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Type hints [[Read1](https://peps.python.org/pep-0483/), [Read2](https://bernat.tech/posts/the-state-of-type-hints-in-python/)]\n",
    "\n",
    "If debugging is our dynamic way of inspecting code, type hints are our way to **statically analyze it**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad40c22",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from typing import Typle, List\n",
    "\n",
    "# With type hints (torch_datapipe_record_pipeline.py, Lines 46-53)\n",
    "def parse_inputs(input_data: Tuple[str, int]) -> [List[int], int]:\n",
    "    text, label = input_data\n",
    "    text = preprocess_text(text=text)\n",
    "    tokens = vocab(tokenizer(text))\n",
    "    return tokens, label\n",
    "\n",
    "\n",
    "# Without type hints\n",
    "def parse_inputs(input_data):\n",
    "    text, label = input_data\n",
    "    text = preprocess_text(text=text)\n",
    "    tokens = vocab(tokenizer(text))\n",
    "    return tokens, label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eafc54b2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Advantages\n",
    "\n",
    "1. Integrated documentation with code $\\rightarrow$ much more readable than docstrings\n",
    "2. Accurate code re-factoring for IDEs\n",
    "3. Allows code auto-completion for IDEs\n",
    "4. Linters (included in IDEs) can tell wrong function calls based on type hints $\\rightarrow$ warnings!!\n",
    "5. We can define compund type like ```List[int]```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821c808b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Disadvantages\n",
    "\n",
    "1. We need at least ```Python 3.6``` (*reasonable given any deep learning framework requirements*)\n",
    "2. May have conflicts with docstrings depending on the tool used\n",
    "3. Minor added computation overhead\n",
    "4. Forces to import all type dependencies, even though they are not used at runtime at all\n",
    "5. Compound type may require some additional operations by the interpreter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57cf23d7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Points [4-5] are solved via post-poned evaluation of annotations (*requires ```Python 3.7```*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e10b5f6f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# w/o post-poned evaluation\n",
    "class A:\n",
    "    def f(self) -> A: # NameError: name 'A' is not defined\n",
    "        pass\n",
    "    \n",
    "# w/ post-poned evaluation\n",
    "from __future__ import annotations\n",
    "\n",
    "class A:\n",
    "    def f(self) -> A:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9429b3c",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### An example\n",
    "\n",
    "We can use Python's reference linter ```mypy``` to run our type hinted code\n",
    "\n",
    "\n",
    "#### Script\n",
    "\n",
    "```mypy_example.py```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "364adc1a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Types of type hints\n",
    "\n",
    "- Nominal types: ```int```, ```float```, ```bool```, etc... (*all bultin type*)\n",
    "- Compound types: ```List[int]```\n",
    "    - We can also define type aliases for readability: ```CustomType = Optional[List[int], Dict[str, str]]```\n",
    "    \n",
    "- Compotional types: ```Union[...]``` (*one of*), ```Intersection[...]``` (*each one*), ```Optional[...]``` (*can be None*)\n",
    "- Generic types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46110c90",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from typing import TypeVar, Generic, Iterable, Iterator\n",
    "\n",
    "T = TypeVar('T')   # must use the same variable name\n",
    "\n",
    "class CustomClass(Generic[T]):\n",
    "    def __init__(self, value: T) -> None:\n",
    "        self.value: T = value\n",
    "            \n",
    "    def get_iterator(values: Iterable[CustomClass[int]]) -> Iterator:\n",
    "        for value in values:\n",
    "            yield value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26e2749b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "####  Proper function overloading\n",
    "\n",
    "Suppose you have the following function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978fd145",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def do_stuff(x: Union[int, List[int]]) -> Union[int, List[int]]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d30c78",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The type hinter understands that you can call ```do_stuff``` with\n",
    "   - ```input x is int returns int```\n",
    "   - ```input x is int returns List[int]```\n",
    "   - ```input x is List[int] returns int```\n",
    "   - ```input x is List[int] returns List[int]```\n",
    "   \n",
    "#### How to avoid this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6244abf0",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "from typing import overload\n",
    "\n",
    "@overload\n",
    "def do_stuff(x: int) -> int:\n",
    "    ...\n",
    "    \n",
    "@overload\n",
    "def do_stuff(x: List[int]) -> List[int]:\n",
    "    ...\n",
    "\n",
    "\n",
    "def do_stuff(x: Union[int, List[int]]) -> Union[int, List[int]]:\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd83e10b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Actually, we should rely on patterns like ```functools.singledispatch``` or [```multipledispatch```](https://pypi.org/project/multipledispatch/)\n",
    "\n",
    "$\\rightarrow$ check [this interesting blog](https://martinheinz.dev/blog/50) about proper function overloading"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175a1459",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What type hints don't do\n",
    "\n",
    "- Runtime type inference $\\rightarrow$ we need some libraries that leverage type hints\n",
    "- No performance tuning $\\rightarrow$ type hints are treated just like comments\n",
    "\n",
    "#### Only type hinted code is type-checked!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "861eb0cb",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Bonus: type hints and Sphinx for merging documentation\n",
    "\n",
    "We can remove all typing information from docstrings and infer them from type hints\n",
    "\n",
    "Sphinx has the plugin [```agronoholm/sphinx-autodoc-typehints```](https://github.com/agronholm/sphinx-autodoc-typehints)\n",
    "\n",
    "Then add the following extensions to Sphinx's ```conf.py```\n",
    "\n",
    "```\n",
    "extensions = [\"sphinx.ext.autodoc\", \"sphinx_autodoc_typehints\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb1b7cbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Typechecking\n",
    "\n",
    "Type hints do not perform type checking at execution time!\n",
    "\n",
    "$\\rightarrow$ you may still pass wrong typed data without raising any error\n",
    "\n",
    "#### Typechecking leverages type hints to perform execution control\n",
    "\n",
    "There exist several libraries for doing typechecking: [Enforce](https://pypi.org/project/enforce/), [Pydantic](https://pypi.org/project/pydantic/), [Pytypes](https://pypi.org/project/pytypes/), and [Typeguard](https://pypi.org/project/typeguard/) are among the most popular ones"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72270dae",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [An example with Pydantic](https://lyz-code.github.io/blue-book/coding/python/pydantic_functions/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20990521",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import validate_arguments, ValidationError\n",
    "\n",
    "\n",
    "@validate_arguments\n",
    "def repeat(s: str, count: int, *, separator: bytes = b'') -> bytes:\n",
    "    b = s.encode()\n",
    "    return separator.join(b for _ in range(count))\n",
    "\n",
    "\n",
    "a = repeat('hello', 3)\n",
    "print(a)\n",
    "#> b'hellohellohello'\n",
    "\n",
    "b = repeat('x', '4', separator=' ')\n",
    "print(b)\n",
    "#> b'x x x x'\n",
    "\n",
    "try:\n",
    "    c = repeat('hello', 'wrong')\n",
    "except ValidationError as exc:\n",
    "    print(exc)\n",
    "    \"\"\"\n",
    "    1 validation error for Repeat\n",
    "    count\n",
    "      value is not a valid integer (type=type_error.integer)\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f1c7d2",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Logging [[Read1](https://martinheinz.dev/blog/24)]\n",
    "\n",
    "Not having any logs from your application can make it very difficult to troubleshoot any bugs.\n",
    "\n",
    "$\\rightarrow$ replace ```print(...)``` with ```logging.info(...)```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "961c979a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(\n",
    "    filename='application.log',\n",
    "    level=logging.WARNING,\n",
    "    format= '[%(asctime)s] {%(pathname)s:%(lineno)d} %(levelname)s - %(message)s',\n",
    "    datefmt='%H:%M:%S'\n",
    ")\n",
    "\n",
    "logging.error(\"Some serious error occurred.\")\n",
    "logging.warning('Function you are using is deprecated.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82775534",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Decorating functions to avoid messing up their body"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14449c67",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from functools import wraps, partial\n",
    "import logging\n",
    "\n",
    "def attach_wrapper(obj, func=None):  # Helper function that attaches function as attribute of an object\n",
    "    if func is None:\n",
    "        return partial(attach_wrapper, obj)\n",
    "    setattr(obj, func.__name__, func)\n",
    "    return func\n",
    "\n",
    "def log(level, message):  # Actual decorator\n",
    "    def decorate(func):\n",
    "        logger = logging.getLogger(func.__module__)  # Setup logger\n",
    "        formatter = logging.Formatter(\n",
    "            '%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "        handler = logging.StreamHandler()\n",
    "        handler.setFormatter(formatter)\n",
    "        logger.addHandler(handler)\n",
    "        log_message = f\"{func.__name__} - {message}\"\n",
    "\n",
    "        @wraps(func)\n",
    "        def wrapper(*args, **kwargs):  # Logs the message and before executing the decorated function\n",
    "            logger.log(level, log_message)\n",
    "            return func(*args, **kwargs)\n",
    "\n",
    "        @attach_wrapper(wrapper)  # Attaches \"set_level\" to \"wrapper\" as attribute\n",
    "        def set_level(new_level):  # Function that allows us to set log level\n",
    "            nonlocal level\n",
    "            level = new_level\n",
    "\n",
    "        @attach_wrapper(wrapper)  # Attaches \"set_message\" to \"wrapper\" as attribute\n",
    "        def set_message(new_message):  # Function that allows us to set message\n",
    "            nonlocal log_message\n",
    "            log_message = f\"{func.__name__} - {new_message}\"\n",
    "\n",
    "        return wrapper\n",
    "    return decorate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bfaf6f",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Example Usage\n",
    "@log(logging.WARN, \"example-param\")\n",
    "def somefunc(args):\n",
    "    return args\n",
    "\n",
    "somefunc(\"some args\")\n",
    "somefunc.set_level(logging.CRITICAL)  # Change log level by accessing internal decorator function\n",
    "somefunc.set_message(\"new-message\")  # Change log message by accessing internal decorator function\n",
    "somefunc(\"some args\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ecc7e3a",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Overwriting ```__repr__``` and ```__str__``` for debugging\n",
    "\n",
    "It might be a good idea to overwrite these methods to better inspect objects via logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7c7cfb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Circle:\n",
    "    def __init__(self, x, y, radius):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.radius = radius\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"Rectangle({self.x}, {self.y}, {self.radius})\"\n",
    "\n",
    "...\n",
    "c = Circle(100, 80, 30)\n",
    "repr(c)\n",
    "# Circle(100, 80, 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "049af20d",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tracebacks\n",
    "\n",
    "https://martinheinz.dev/blog/66"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba46740",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Assertions\n",
    "\n",
    "In addition to typechecking, you may also want to enforce specific sanity checks: pre-conditions, post-conditions, invariants\n",
    "\n",
    "- Correct batches\n",
    "- Correct pre-processing\n",
    "- etc...\n",
    "\n",
    "$\\rightarrow$ In the simplest form, we can insert assertions in our code: ```assert condition, message```\n",
    "\n",
    "#### Make sure you use assertions for debugging only!\n",
    "\n",
    "Proper control flow (e..g, ```if-then-else```) is the recommended way for handling multiple behaviours\n",
    "\n",
    "Assertions may be disabled via ```python -0 myscript.py```, thus, your code relying on assertion may not perform any sanity check at all\n",
    "\n",
    "$\\rightarrow$ In practice, in research, we are never doing production code, thus we may not need to follow these advices slavishly\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06580bf3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Unit tests [[Read1](https://martinheinz.dev/blog/7)]\n",
    "\n",
    "A better way to make use of assertions to define sanity checks is to define proper unit tests.\n",
    "\n",
    "Python offers the ```pytest``` and ```unittest``` libraries to define unit tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "405a3740",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Testing exception raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f9b5e599",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pytest'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13491/1544975204.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpytest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_my_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mpytest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraises\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mException\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'My Message'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mmy_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pytest'"
     ]
    }
   ],
   "source": [
    "import pytest\n",
    "\n",
    "def test_my_function():\n",
    "    with pytest.raises(Exception, match='My Message') as e:\n",
    "        my_function()\n",
    "        assert e.type is ValueError"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed0a056",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Testing stout and stderr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9732bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_my_function(capsys):\n",
    "    my_function()  # function that prints stuff\n",
    "    captured = capsys.readouterr()  # Capture output\n",
    "    assert f\"Received invalid message ...\" in captured.out  # Test stdout\n",
    "    assert f\"Fatal error ...\" in captured.err  # Test stderr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aedb66a1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Patching objects\n",
    "\n",
    "We can replace objects used in fucntions under test with ```mock.patch```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916ad95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import mock\n",
    "\n",
    "def test_my_function():\n",
    "    # We are replacing 'method_of_class' to return None\n",
    "    with mock.patch.object(SomeClass, 'method_of_class', return_value=None) as mock_method:\n",
    "        instance = SomeClass()\n",
    "        instance.method_of_class('arg')\n",
    "\n",
    "        mock_method.assert_called_with('arg')  # True\n",
    "\n",
    "def test_my_function():\n",
    "    r = Mock()\n",
    "    r.content = b'{\"success\": true}'\n",
    "    with mock.patch('requests.get', return_value=r) as get:  # Avoid doing actual GET request\n",
    "        some_function()  # Function that calls requests.get\n",
    "        get.assert_called_once()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224d4439",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Fixtures\n",
    "\n",
    "If we have multiple unit tests, you can share fixtures (i.e., test init functions) between unit tests via ```conftest.py```\n",
    "\n",
    "It is a file that stores all share fixtures\n",
    "\n",
    "Pytest automatically discovers them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6200bf97",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import pytest, os\n",
    "\n",
    "# Executed before any pytest\n",
    "@pytest.fixture(scope='function')\n",
    "def reset_sqlite_db(request):\n",
    "    path = request.param  # Path to database file\n",
    "    with open(path, 'w'): pass\n",
    "    yield None\n",
    "    os.remove(path)\n",
    "    \n",
    "# Defining pytest that initially invokes the above fixture\n",
    "@pytest.mark.parametrize('reset_sqlite_db', ['/tmp/test_db.sql'], indirect=True)\n",
    "def test_send_message(reset_sqlite_db):\n",
    "    ...  # Perform tests that access prepared SQLite database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed1f6b3",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Profiling [[Read1](https://martinheinz.dev/blog/13), [Read2](https://martinheinz.dev/blog/68), [Read3](https://martinheinz.dev/blog/83), [Read4](https://martinheinz.dev/blog/64)]\n",
    "\n",
    "Debugging and typechecking are not the only way to find a bug.\n",
    "\n",
    "$\\rightarrow$ we can also monitor employed resources to gather insights about efficiency, memory leaks and potential bottlenecks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc8d3d3",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using ```timeit```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1caa0cd9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# In the simplest form:\n",
    "python -m timeit \"7 + 28\"\n",
    "50000000 loops, best of 5: 5.72 nsec per loop\n",
    "\n",
    "# Creates \"x\" variable before running the test\n",
    "python -m timeit -s \"x = range(10000)\" \"sum(x)\"\n",
    "2000 loops, best of 5: 160 usec per loop"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7af4d47",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using ```pyperf```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cbd108b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Uses \"-l\" and \"-n\" instead of \"-n\" and \"-r\" respectively\n",
    "python -m pyperf timeit -s \"x = range(10000)\" \"sum(x)\" -o result.json\n",
    ".....................\n",
    "Mean +- std dev: 157 us +- 12 us\n",
    "\n",
    "python -m pyperf stats result.json\n",
    "\n",
    "Total duration: 13.4 sec\n",
    "Start date: 2022-09-09 12:36:27\n",
    "End date: 2022-09-09 12:36:42\n",
    "...\n",
    "\n",
    "  0th percentile: 134 us (-9% of the mean) -- minimum\n",
    "  5th percentile: 135 us (-9% of the mean)\n",
    " 25th percentile: 137 us (-8% of the mean) -- Q1\n",
    " 50th percentile: 141 us (-4% of the mean) -- median\n",
    " 75th percentile: 161 us (+9% of the mean) -- Q3\n",
    " 95th percentile: 163 us (+10% of the mean)\n",
    "100th percentile: 168 us (+14% of the mean) -- maximum\n",
    "\n",
    "python3 -m pyperf hist result.json\n",
    "\n",
    "python3 -m pyperf hist result.json --bins 10\n",
    "133 us: 13 ############################################################\n",
    "136 us: 14 #################################################################\n",
    "139 us:  6 ############################\n",
    "143 us:  1 #####\n",
    "146 us:  0 |\n",
    "150 us:  0 |\n",
    "153 us:  0 |\n",
    "156 us:  7 #################################\n",
    "160 us: 17 ###############################################################################\n",
    "163 us:  0 |\n",
    "167 us:  2 #########"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ceb7a29",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using ```cProfile```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a58caa1",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m4\u001b[0m\n\u001b[0;31m    Ordered by: internal time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "!python -m cProfile -s time your_script.py\n",
    "         1297 function calls (1272 primitive calls) in 11.081 seconds\n",
    "\n",
    "   Ordered by: internal time\n",
    "\n",
    "   ncalls  tottime  percall  cumtime  percall filename:lineno(function)\n",
    "        3   11.079    3.693   11.079    3.693 slow_program.py:4(exp)\n",
    "        1    0.000    0.000    0.002    0.002 {built-in method _imp.create_dynamic}\n",
    "      4/1    0.000    0.000   11.081   11.081 {built-in method builtins.exec}\n",
    "        6    0.000    0.000    0.000    0.000 {built-in method __new__ of type object at 0x9d12c0}\n",
    "        6    0.000    0.000    0.000    0.000 abc.py:132(__new__)\n",
    "       23    0.000    0.000    0.000    0.000 _weakrefset.py:36(__init__)\n",
    "      245    0.000    0.000    0.000    0.000 {built-in method builtins.getattr}\n",
    "        2    0.000    0.000    0.000    0.000 {built-in method marshal.loads}\n",
    "       10    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:1233(find_spec)\n",
    "      8/4    0.000    0.000    0.000    0.000 abc.py:196(__subclasscheck__)\n",
    "       15    0.000    0.000    0.000    0.000 {built-in method posix.stat}\n",
    "        6    0.000    0.000    0.000    0.000 {built-in method builtins.__build_class__}\n",
    "        1    0.000    0.000    0.000    0.000 __init__.py:357(namedtuple)\n",
    "       48    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:57(_path_join)\n",
    "       48    0.000    0.000    0.000    0.000 <frozen importlib._bootstrap_external>:59(<listcomp>)\n",
    "        1    0.000    0.000   11.081   11.081 slow_program.py:1(<module>)\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1059e5dd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Just shows function calls!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500869b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using ```line_profiler```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee80d41",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "kernprof -l -v some-code.py  # This might take a while...\n",
    "\n",
    "Wrote profile results to some-code.py.lprof\n",
    "Timer unit: 1e-06 s\n",
    "\n",
    "Total time: 13.0418 s\n",
    "File: some-code.py\n",
    "Function: exp at line 3\n",
    "\n",
    "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
    "==============================================================\n",
    "     3                                           @profile\n",
    "     4                                           def exp(x):\n",
    "     5         1          4.0      4.0      0.0      getcontext().prec += 2\n",
    "     6         1          0.0      0.0      0.0      i, lasts, s, fact, num = 0, 0, 1, 1, 1\n",
    "     7      5818       4017.0      0.7      0.0      while s != lasts:\n",
    "     8      5817       1569.0      0.3      0.0          lasts = s\n",
    "     9      5817       1837.0      0.3      0.0          i += 1\n",
    "    10      5817       6902.0      1.2      0.1          fact *= i\n",
    "    11      5817       2604.0      0.4      0.0          num *= x\n",
    "    12      5817   13024902.0   2239.1     99.9          s += num / fact\n",
    "    13         1          5.0      5.0      0.0      getcontext().prec -= 2\n",
    "    14         1          2.0      2.0      0.0      return +s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cd867ad",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using ```pyheat```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938311cb",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "!pyheat some-code.py --out image_file.png"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2aeec3d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "<center>\n",
    "<div>\n",
    "<img src=\"Images/Lecture-4/pyheat.png\" width=\"600\"/>\n",
    "</div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2591ce7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using decorators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60440ce5",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate_time(\n",
    "        func: Callable\n",
    "):\n",
    "    def compute_time(\n",
    "            *args,\n",
    "            **kwargs\n",
    "    ):\n",
    "        start_time = time.perf_counter()    # <---\n",
    "        func_result = func(*args, **kwargs)\n",
    "        end_time = time.perf_counter()      # <---\n",
    "        total_time = end_time - start_time\n",
    "        print(f'Function {func {func.__module__} -- {func.__name__} took {total_time} seconds')\n",
    "        return func_result\n",
    "\n",
    "    return compute_time\n",
    "\n",
    "@evaluate_time\n",
    "def load_ibm2015_dataset(\n",
    "        samples_amount: int = -1\n",
    "):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f26b5e",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Using ```memory_profiler``` and ```psutil```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a1b43a",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "python -m memory_profiler some-code.py\n",
    "Filename: some-code.py\n",
    "\n",
    "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
    "============================================================\n",
    "    15   39.113 MiB   39.113 MiB            1   @profile\n",
    "    16                                          def memory_intensive():\n",
    "    17   46.539 MiB    7.426 MiB            1       small_list = [None] * 1000000\n",
    "    18  122.852 MiB   76.312 MiB            1       big_list = [None] * 10000000\n",
    "    19   46.766 MiB  -76.086 MiB            1       del big_list\n",
    "    20   46.766 MiB    0.000 MiB            1       return small_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8641fbd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Coding Best Practices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15c87e28",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### What are we going to see\n",
    "\n",
    "- Variable naming\n",
    "- Comments\n",
    "- Nesting\n",
    "- Inheritance\n",
    "- Abstraction\n",
    "- Organization\n",
    "- Code optimization\n",
    "\n",
    "All taken from the wonderful youtube channel of [```CodeAeshetic```](https://www.youtube.com/@CodeAesthetic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1c913",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Variable Naming [[Read1](https://www.youtube.com/watch?v=-J3wNP6u5YU&t=43s)]\n",
    "\n",
    "We've talked about debugging, but can we prevent incentivizing our 'internal demon' about making errors?\n",
    "\n",
    "$\\rightarrow$ Yes! F\\*\\*\\*ing use good naming convention!\n",
    "\n",
    "#### Why? Because we spend more time reading code than writing code!\n",
    "\n",
    "#### Don'ts\n",
    "\n",
    "- Avoid single letter variable names (*wtf?*)\n",
    "- Avoid abbreviations (*may induce wrong interpretation*)\n",
    "- Don't put types in variable names (e.g., my_output_str, BaseModel)\n",
    "\n",
    "#### Do's\n",
    "\n",
    "- Put units in variable names (e.g., ```float sleep_time_seconds```) $\\rightarrow$ if we can use a custom type, it is much better\n",
    "- Refactor code to avoid general functions like ```utilities``` $\\rightarrow$ these functions usually can be moved to specific classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79ea675",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Comments\n",
    "\n",
    "Writing comments is usually the best way of explaining the code, increasing readability\n",
    "\n",
    "But, extremes (i.e., 'no comments at all' or 'wall of texts')  can be potentially harmful\n",
    "\n",
    "Comments get 'bugs' like code (i.e., code is updated but not comments!) $\\rightarrow$ the cake is a lie\n",
    "\n",
    "Code should speak by itself, we should really comment on WHY that code is needed rather on WHAT that code is doing\n",
    "    - Code Documentation: how code is used (e.g., ```Sphinx```)\n",
    "    - Code Comments: how code works\n",
    "\n",
    "#### Should we always avoid comments? Hell no!\n",
    "\n",
    "- In many cases, we might have hard to grasp code (especially when doing code optimization)\n",
    "- If we are following a particular reference (e.g., formula, paper, github issue, etc...)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "043816bd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Never a Nester\n",
    "\n",
    "''*If you need more than 3 levels of indentation, you're screwed anyway, and should fix your program*\" - from Linux style guidelines\n",
    "\n",
    "Nesting means adding inner code blocks to your code (e.g., function, control flow, etc...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc00e13",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def calculate(bottom: int, top: int):        # <--- Level 1\n",
    "    if top > bottom:                         # <--- Level 2\n",
    "        sum = 0\n",
    "        for number in range(bottom, top):    # <--- Level 3\n",
    "            if number % 2 == 0:              # <--- Level 4\n",
    "                sum += number\n",
    "        return sum\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba797f52",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What can we do?\n",
    "\n",
    "1. Extraction: move a block to a separate function\n",
    "2. Inversion: flip control flow to avoid nesting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac97f510",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6541ae2",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def filter_number(number: int):\n",
    "    if number % 2 == 0:\n",
    "        return number\n",
    "    return 0\n",
    "\n",
    "def calculate(bottom: int, top: int):        \n",
    "    if top > bottom:                         \n",
    "        sum = 0\n",
    "        for number in range(bottom, top):    \n",
    "            sum += filter_number(number)\n",
    "        return sum\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c52d70",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Inversion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a224126c",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def filter_number(number: int):\n",
    "    if number % 2 == 0:\n",
    "        return number\n",
    "    return 0\n",
    "\n",
    "def calculate(bottom: int, top: int):\n",
    "    if top < bottom:\n",
    "        return 0\n",
    "                             \n",
    "    sum = 0\n",
    "    for number in range(bottom, top):    \n",
    "        sum += filter_number(number)\n",
    "    return sum\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76df5b15",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Abstraction\n",
    "\n",
    "When writing code, we usually learn that **code repetition** is **bad** and that **abstraction** is **good**\n",
    "\n",
    "$\\rightarrow$ We really need to understand the side-effect of abstraction: **coupling**\n",
    "\n",
    "#### Worth it\n",
    "\n",
    "- Many implementations with complex construction\n",
    "- Deferred execution from creation\n",
    "\n",
    "#### Not worth it\n",
    "\n",
    "- Sharing member variables\n",
    "- Not valuable for abstraction user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0726e5",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Inheritance and Composition\n",
    "\n",
    "Inheritance is one of the most popular features of OOP\n",
    "\n",
    "Two functionalities\n",
    "\n",
    "- Re-use code $\\rightarrow$ extending functionalities\n",
    "- Abstraction $\\rightarrow$ hiding details about from which class a method is being invoked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9157328",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Image(ABC):\n",
    "    \n",
    "    def resize(scale: float):\n",
    "        ...\n",
    "        \n",
    "    def flip():\n",
    "        ...\n",
    "        \n",
    "    @abc.abstractmethod\n",
    "    def save():\n",
    "        pass\n",
    "\n",
    "class PngImage(Image):\n",
    "    \n",
    "    def save():\n",
    "        ...\n",
    "        \n",
    "class JpegImage(Image):\n",
    "    \n",
    "    def save():\n",
    "        ...\n",
    "        \n",
    "# Exception!\n",
    "class DrawableImage(Image):\n",
    "    \n",
    "    def save():\n",
    "        raise Exception('Not supported')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9223e5d",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "class Image(ABC):\n",
    "    ...\n",
    "    \n",
    "class FileImage(Image):\n",
    "    \n",
    "    @abc.abstractmethod\n",
    "    def save():\n",
    "        pass\n",
    "    \n",
    "class PngImage(FileImage):\n",
    "    ...\n",
    "    \n",
    "class JpegImage(FileImage):\n",
    "    ...\n",
    "    \n",
    "class DrawableImage(Image):\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c42d40a0",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Such a refactoring can be quite costly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e451cc06",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### What about Composition?\n",
    "\n",
    "Inheritance breaks down as soon we find an exception to our 'perfect' design (i.e., when we grab common terms to define a shared parent class)\n",
    "\n",
    "$\\rightarrow$ In these cases, we can rely on Composition!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a694f120",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class Image(ABC):\n",
    "    \n",
    "    def resize(scale: float):\n",
    "        ...\n",
    "        \n",
    "    def flip():\n",
    "        ...\n",
    "        \n",
    "class PngImage:\n",
    "    \n",
    "    def save(image: Image):\n",
    "        ...\n",
    "        \n",
    "class JpegImage:\n",
    "    \n",
    "    def save(image: Image):\n",
    "        ...\n",
    "        \n",
    "        \n",
    "class DrawableImage:\n",
    "    \n",
    "    def __init__(self, image: Image):\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8544295",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "\n",
    "Pros:\n",
    "\n",
    "- Reduces coupling to re-used code\n",
    "- Adaptable as new requirements come in\n",
    "\n",
    "Cons:\n",
    "\n",
    "- Boilerplate code to inizialize internal types\n",
    "- We may need to write wrapper methods to expose information from internal types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b9a53ae",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code Optimization\n",
    "\n",
    "Don't immediately focus on performance (i.e., code optimization), but rather on velocity of implementation and ease of use\n",
    "\n",
    "$\\rightarrow$ Only care about performance when strictly needed! \n",
    "$\\rightarrow$ Is it worht it?\n",
    "$\\rightarrow$ Does it lead to less readable code?\n",
    "\n",
    "#### Example:\n",
    "\n",
    "Don't worry if your training routine is taking a lot, focus first on its correctness and test your code with small controlled inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0f6856",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Tensorflow and PyTorch Best Practices\n",
    "\n",
    "### Modeling ([Karpathy's blog](https://karpathy.github.io/2019/04/25/recipe/))\n",
    "- Inspect data\n",
    "- Start simple\n",
    "- Overfit\n",
    "- Apply some regularizations\n",
    "- Hyper-parameters tuning\n",
    "\n",
    "### Scripting\n",
    "- File Organization\n",
    "- Sequential layers\n",
    "- Calling layers\n",
    "- Training and evaluation modes\n",
    "- Mixing operations\n",
    "- Detaching\n",
    "- Numerical stability\n",
    "- Shuffling data\n",
    "- Gradient clipping\n",
    "- tf.reshape/th.view vs tf.transpose/th.permute\n",
    "- Squeezing\n",
    "- Working with GPU devices\n",
    "- Freeing GPU memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4301703c",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Modeling\n",
    "\n",
    "*Because, eventually, we all prefer a todo listing...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfe98dd",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Intro\n",
    "\n",
    "Neural networks are not a plug-and-play module that is expected to work effortlessly\n",
    "\n",
    "Instead, neural networks often fail silently (*no exceptions!*) and can still manage to reach some satisfying result (*unexpected*)\n",
    "   - Leakage\n",
    "   - Data errors\n",
    "   - Wrong initialization, regularization, optimization, etc...\n",
    "    \n",
    "#### What you should do (*in pills*)\n",
    "\n",
    "- Start slow $\\rightarrow$ don't be eager to test out your super fancy model on your ultra fancy data\n",
    "- Check your data attentively\n",
    "- Start simple $\\rightarrow$ progressively introduce complexity\n",
    "- Hammer your model until it is sufficiently powerful and regularized to work well"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7b4bd12",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Become one with the data\n",
    "\n",
    "Intuitively, we never start from modeling, but rather we look at data\n",
    "\n",
    "- Understand relevant features for addressing the task\n",
    "- Spot outliers (*may be symptomatic of data collection errors*)\n",
    "- Spot errors (e.g., duplicates, wrong labeling)\n",
    "- Check data distributions\n",
    "- Identify biases\n",
    "- Identify possible correct pre-processing steps\n",
    "- Helps in understanding model post-training evaluation (*error analysis*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ee85f0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Start simple\n",
    "\n",
    "We are not ready yet to plug-in our fancy model\n",
    "\n",
    "- Write a training/evaluation skeleton\n",
    "- Test simple baselines (*how far can they go?*) $\\rightarrow$ downplaying possible scripting errors\n",
    "- Avoid any unnecessary complexity $\\rightarrow$ pick the simplest setting possible\n",
    "- Overfit one single batch $\\rightarrow$ spotting errors, evaluate model capacity, evaluate data\n",
    "- Check learning curves\n",
    "- Inspect model prediction dynamics $\\rightarrow$ gives good intuition of model training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c014719e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Overfit\n",
    "\n",
    "Pick a large enough model that is able to overfit $\\rightarrow$ we understand that the task is *solvable* on training data\n",
    "\n",
    "- Pick existing models (*even their simplest version*) rather than making custom ones\n",
    "- Progressively introduce complexity $\\rightarrow$ multiple inputs, larger inputs, etc..\n",
    "- Pay attention to employed optimizers $\\rightarrow$ weight decay, learning rate decay"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "252e732f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Regularize\n",
    "\n",
    "Once we have a big enough model, we have to regularize it to allow better generalization capabilities\n",
    "\n",
    "- Add more data (*if you can!*) $\\rightarrow$ data-augmentation, real data, synthetic data\n",
    "- Check spurious inputs\n",
    "- Decrease model size\n",
    "- Decrease batch size (*if you are using batch normalization*)\n",
    "- Dropout\n",
    "- Weight decay\n",
    "- Early stopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8db45b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Tuning\n",
    "\n",
    "To find a good regularized model, we may consider a hyper-parameter calibration routine\n",
    "\n",
    "- Random search (*it usually works quite well to explore the hyper-parameter space*)\n",
    "- Bayesian optimization (e.g., Optuna)\n",
    "- Use your brain $\\rightarrow$ in many cases, you may need to think about the valid search space"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e6d48",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scripting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08f20b72",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### File Organization\n",
    "\n",
    "Split your model into individual layers and losses to\n",
    "\n",
    "- Enhance re-usability (*easier to spot errors*)\n",
    "- Enhance readability (*top-down view of a model*)\n",
    "\n",
    "The same applies for nested models, layers and losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ad35ea",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# losses.py\n",
    "class CustomLoss(th.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        ...\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        ...\n",
    "        \n",
    "# layers.py\n",
    "class CustomLayer(th.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        ...\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        ...\n",
    "        \n",
    "# models.py\n",
    "class CustomModel(th.nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        self.layer = CustomLayer(...)\n",
    "        self.loss_op = CustomLoss(...)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38a19db7",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In Tensorflow this is particularly recommended when considering ```tf.function```\n",
    "\n",
    "#### tf.function covers function nesting\n",
    "\n",
    "If a function invokes other functions, you just need to decorate the top-level function with ```tf.function```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f95d072",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    \n",
    "    def loss_op(self, x, y, training=False):\n",
    "        output = self.model(x, training=training)\n",
    "        loss = ...\n",
    "        return loss\n",
    "\n",
    "    def train_op(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss_op(x=x, y=y, training=True)\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        return grads\n",
    "    \n",
    "    @tf.function\n",
    "    def batch_fit(self, x, y):\n",
    "        loss, grads = self.train_op(x, y)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def batch_evaluate(self, x, y):\n",
    "        return self.loss_op(x=x, y=y, training=False)\n",
    "        \n",
    "    @tf.function\n",
    "    def batch_predict(self, x):\n",
    "        return self.model(x, training=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b5db125",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Sequential Layers\n",
    "\n",
    "In many cases, we may have to define a sequential network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588f7866",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Which one do you use?\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-1-1.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-1-2.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-1-3.png\" width=\"1100\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(A)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(B)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(C)</strong> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021d1272",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### (A) is the best choice\n",
    "\n",
    "- [**TH**] Uses nn.Sequential(...) to define a sequential network $\\rightarrow$ higher efficiency, readibility\n",
    "- [**TF**] Likewise, use ```tf.keras.Sequential``` in tensorflow\n",
    "    \n",
    "#### (B) may give some problems with list wrapping\n",
    "\n",
    "- [**TH**] Consider using ```th.nn.ModuleList(...)``` rather than a list\n",
    "- [**TF**] It is fine to list wrapping multiple layers, but the recommended way is to use ```tf.keras.Sequential```\n",
    "    \n",
    "#### (C) is terrible!\n",
    "\n",
    "- Generates layers at each forward pass $\\rightarrow$ losing track of model weights to update\n",
    "- You need to define layers in the ```__init__(...)``` method so that model weights are kept throughout the life the of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561da159",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Calling layers\n",
    "\n",
    "Both Tensorflow and Pytorch implement layers as callable objects\n",
    "\n",
    "Always invoke your layer/model as ```layer(...)``` and ```model(...)```, respectively.\n",
    "\n",
    "#### Never invoke ```call(...)``` or ```forward(...)``` explicitly!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06c1d94a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training and Evaluation modes\n",
    "\n",
    "Torch has two model modalities: ```model.train()``` and ```model.eval()```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053051f9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Which one do you use?\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-3-1.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-3-2.png\" width=\"1100\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(A)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(B)</strong> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef5e4f",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Both are correct!\n",
    "\n",
    "#### Model.eval()\n",
    "\n",
    "- Just changes model execution so that layers like Dropout, BatchNorm can execute correctly\n",
    "\n",
    "#### torch.no_grad()\n",
    "\n",
    "- Disables automatic differentiation saving up memory and time\n",
    "\n",
    "\n",
    "In the common case where you don't compute any gradient during evaluation, you can use both to gain some speed-up and use less memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d6b932",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Beware of incorrect behaviours!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84fb984e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, epochs, train_steps, train_data_iterator, val_steps, val_data_iterator):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        epoch_train_iterator = train_data_iterator()\n",
    "        for step in range(train_steps):\n",
    "            batch = next(epoch_train_iterator)\n",
    "            batch_loss = model.batch_fit(*batch)\n",
    "            \n",
    "        # Get loss on validation set\n",
    "        val_loss, val_metrics = evaluate(model=model, steps=val_steps, data_iterator=val_data_iterator)\n",
    "                \n",
    "                \n",
    "def evaluate(model, steps, data_iterator):\n",
    "    model.eval()\n",
    "    ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45979197",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Tensorflow is as straightforward as Pytorch\n",
    "\n",
    "You just have to remember to call your model with ```training=True|False``` for training and evaluation modes, respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29fefe8b",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "    def loss_op(self, x, y, training=False):\n",
    "        output = self.model(x, training=training)  # <---\n",
    "        loss = ...\n",
    "        return loss\n",
    "\n",
    "    def train_op(self, x, y):\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss = self.loss_op(x=x, y=y, training=True)   # <---\n",
    "        grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "        return grads\n",
    "    \n",
    "    @tf.function\n",
    "    def batch_fit(self, x, y):\n",
    "        loss, grads = self.train_op(x, y)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        return loss\n",
    "    \n",
    "    @tf.function\n",
    "    def batch_evaluate(self, x, y):\n",
    "        return self.loss_op(x=x, y=y, training=False)   # <---\n",
    "        \n",
    "    @tf.function\n",
    "    def batch_predict(self, x):\n",
    "        return self.model(x, training=False)  # <---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ead0ddf",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixing operations\n",
    "\n",
    "Consider the following code snippet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b676d073",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy version\n",
    "loss = np.square(y_pred - y_true).sum()\n",
    "\n",
    "# Torch version\n",
    "loss = (y_pred - y_true).pow(2).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13dbefa9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "The numpy code is always run on the CPU, while the torch code may also run on the GPU\n",
    "\n",
    "- Avoid mixing numpy and torch operations in ```forward(...)``` method since numpy operations slow down your code execution!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f71b4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Detaching\n",
    "\n",
    "How to properly collect model outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baede4ac",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Which one do you use?\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-2-1.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-2-2.png\" width=\"1100\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(A)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(B)</strong> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70abf95",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### [TH] Detaching is need!\n",
    "\n",
    "- Remove tensor from torch tracking for automatic differentation\n",
    "- If you don't do that, the unnecessary recording of these tensors slows down your program execution!\n",
    "\n",
    "#### [TF] use ```tensor.numpy()```\n",
    "\n",
    "- If your operation is outside the tensorflow graph, you receive a ```tf.EagerTensor``` storing numerical content (based on provided inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c3d73f",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Numerical Stability\n",
    "\n",
    "Mathematical correctness of your code doesn't necessarily translates to correct results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebcf1b9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Some examples\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-4-1.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-4-2.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-4-3.png\" width=\"1100\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(A)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(B)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(C)</strong> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7fb0998",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Stable versions\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-5-1.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-5-2.png\" width=\"1100\"/> </td>\n",
    "<td> <img src=\"Images/Lecture-4/th-examples-5-3.png\" width=\"1100\"/> </td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(A)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(B)</strong> </td>\n",
    "<td style=\"text-align: center; vertical-align: middle;\"> <strong>(C)</strong> </td>\n",
    "</tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca6e7a7",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Shuffling data\n",
    "\n",
    "One common error is to not appropriately shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1fd180",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Torch (torch_datapipe_example.py, Lines 92-96)\n",
    "data_generator = partial(self.light_iterator, df=df)\n",
    "data = IterableWrapper(data_generator(), deepcopy=False)\n",
    "\n",
    "if shuffle:\n",
    "    data = data.shuffle(buffer_size=100)    # <---\n",
    "    \n",
    "#------------------------------------------------------------------------------------------\n",
    "    \n",
    "# Tensorflow (tf_data_pipeline_gen.py, Lines 65-72)\n",
    "data_generator = partial(self.light_iterator, df=df)\n",
    "data = tf.data.Dataset.from_generator(generator=data_generator,\n",
    "                                      output_signature=(\n",
    "                                          tf.TensorSpec(shape=(), dtype=tf.string),\n",
    "                                          tf.TensorSpec(shape=(), dtype=tf.int64)\n",
    "                                      ))\n",
    "if shuffle:\n",
    "    data = data.shuffle(buffer_size=100)     # <---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbb8a9",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Beware of buffer_size\n",
    "\n",
    "These data pipeline APIs work by setting up a buffer from which sampling random examples.\n",
    "\n",
    "If your buffer is too small you may just sampling class-equivalent examples!\n",
    "\n",
    "- Always pre-shuffle your data (if possible)\n",
    "- Set a buffer_size equal to your data size (if not too big)\n",
    "- Inspect your data stream for sanity check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e52b96",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient clipping\n",
    "\n",
    "In many cases, you may want to clip gradients to increase model training stability\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"Images/Lecture-4/gradient_clipping.png\" width=\"1000\"/>\n",
    "</div>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9e7b33",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Torch\n",
    "optimizer.zero_grad()\n",
    "loss.backward()\n",
    "torch.nn.utils.clip_grad_norm(model.parameters(), max_norm=10)\n",
    "\n",
    "# Tensorflow\n",
    "grads = tape.gradient(loss, self.model.trainable_variables)\n",
    "grads, _ = tf.clip_by_global_norm(grads, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0234c4",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### tf.reshape/th.view vs tf.transpose/th.permute\n",
    "\n",
    "In many cases, we may erroneously use one operation in place of the other one!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "572d377d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.reshape(tf.range(6), [2, 3])\n",
    "# <tf.Tensor: shape=(2, 3), dtype=int32, numpy=\n",
    "#  array([[0, 1, 2], [3, 4, 5]], dtype=int32)>\n",
    "\n",
    "tf.reshape(x, [3, 2])\n",
    "# <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
    "# array([[0, 1],\n",
    "#        [2, 3],\n",
    "#        [4, 5]], dtype=int32)>\n",
    "\n",
    "tf.transpose(x)\n",
    "# <tf.Tensor: shape=(3, 2), dtype=int32, numpy=\n",
    "# array([[0, 3],\n",
    "#        [1, 4],\n",
    "#        [2, 5]], dtype=int32)>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8587f535",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Beware of reshaping!\n",
    "\n",
    "If used incorrectly, it may lead to leakage between batch samples! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5744b0b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Squeezing\n",
    "\n",
    "Squeezing is the operation of removing 1-unit dimensions in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d18babcd",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Shape -> [2, 3, 1, 1]\n",
    "x = tf.reshape(tf.range(6), [2, 3, 1, 1])\n",
    "\n",
    "# Shape -> [2, 3]\n",
    "x = tf.squeeze(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9c0316",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "#### Beware of squeezing with batched tensors\n",
    "\n",
    "One time I lost a couple of hours with a strange error...\n",
    "\n",
    "It turned out that the batching with a specific ```batch_size``` led to a batch with a single sample\n",
    "\n",
    "$\\rightarrow$ squeezing without specifying any dimension inherently converted my input 3D tensors to 2D!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e119168",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Working with GPU devices\n",
    "\n",
    "When working with GPUs we have to carefully inspect how these devices are used\n",
    "\n",
    "$\\rightarrow$ this is particularly annoying with Tensorflow!\n",
    "\n",
    "- Tensorflow automatically reserves all available memory from the selected GPU\n",
    "- Moreover, Tensorflow also reserves some memory in all discovered GPUs, even if you are in a single-GPU setting (*efficiency reasons to reduce memory fragmentation*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a5453",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "\n",
    "# Enforces Tensorflow to just use the necessary amount of GPU memory\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "\n",
    "# Limiting visibility (only first gpu)\n",
    "gpu_start_index = 0\n",
    "gpu_end_index = 1\n",
    "tf.config.set_visible_devices(gpus[gpu_start_index:gpu_end_index], \"GPU\")\n",
    "\n",
    "# Setting max GPU memory (e.g., 3GB on first GPU)\n",
    "tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "                                                        [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=3072)])\n",
    "\n",
    "\n",
    "# Torch\n",
    "\n",
    "# Setting max GPU memory (e.g., 30% of total GPU memory)\n",
    "torch.cuda.set_per_process_memory_fraction(0.3, device='cuda:0')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e5e947",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Freeing GPU memory\n",
    "\n",
    "In many cases, you may find yourself in a scenario where multiple models have to be trained (e.g., cross-validation).\n",
    "\n",
    "In these cases, you may need to efficiently allocate/release GPU usage to avoid memory problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310777c9",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Tensorflow\n",
    "from tensorflow.python.keras import backend as K\n",
    "import gc\n",
    "\n",
    "del model\n",
    "gc.collect()\n",
    "K.clear_session()\n",
    "\n",
    "# Torch\n",
    "del model\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccf6776",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Manually freeing GPU memory may not be needed\n",
    "\n",
    "Generally speaking, Tensorflow/Torch might efficiently re-use the previously allocated memory\n",
    "\n",
    "$\\rightarrow$ manually freeing memory might lead to minor code execution speed reductions\n",
    "\n",
    "#### Tensorflow has a problematic GPU memory management\n",
    "\n",
    "According to this [thread](https://github.com/tensorflow/tensorflow/issues/36465), commands like ```K.clear_session()``` may not really work.\n",
    "\n",
    "Instead, the recommended way is to run your train/evaluation routine in a separate process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f59f4d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing\n",
    "\n",
    "process_eval = multiprocessing.Process(target=evaluate, args=(...))\n",
    "process_eval.start()\n",
    "process_eval.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0ae371",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Bonus\n",
    "\n",
    "- Mixed-precision\n",
    "- Gradient accumulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8fbfef",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Mixed-precision\n",
    "\n",
    "In many cases, you may want to speed-up your training by relying on mixed-precision operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7daa61d",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Autocast\n",
    "with torch.cuda.amp.autocast():\n",
    "    outputs = model(inputs)\n",
    "    loss = loss_op(outputs, targets)\n",
    "    \n",
    "# GradScaler\n",
    "scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "loss = ...\n",
    "optimizer = ...\n",
    "\n",
    "scaler.scale(loss).backward()\n",
    "scaler.step(optimizer)\n",
    "scaler.update()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "865318f1",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### torch.cuda.amp.autocast()\n",
    "\n",
    "- Automatically casts down heavy operations (e.g., convolution, matrix multiplication) to 16-bit\n",
    "- Allows mixed-precision computations\n",
    "\n",
    "\n",
    "#### torch.cuda.amp.GradScaler()\n",
    "\n",
    "- Allows to work with 16-bit gradient values while avoid under/over-flows\n",
    "- Scales up loss to avoid underflows\n",
    "- Scale gradient values down during gradient update to ensure correct model weights update"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1e1dbb2",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "In Tensorflow, mixed-precision is pretty easy to setup as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b198ce6e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.experimental.set_policy(policy) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1558391",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Gradient accumulation\n",
    "\n",
    "Gradient accumulation is the technique of accumulating gradients over multiple batches and perform a single cumulative gradient update\n",
    "\n",
    "$\\rightarrow$ allows training with bigger batch sizes to allow for robust optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1830649",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tensorflow\n",
    "\n",
    "A quick way for doing gradient accumulation is to leverage the [```gradient-accumulator```](https://pypi.org/project/gradient-accumulator/) library\n",
    "\n",
    "$\\rightarrow$ since there is no native way of doing gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b6bc8e",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from gradient_accumulator import GradientAccumulateModel\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "model = Model(...)\n",
    "model = GradientAccumulateModel(accum_steps=4, inputs=model.input, outputs=model.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d9487da",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c126be59",
   "metadata": {},
   "outputs": [],
   "source": [
    "accumulation_size = 4\n",
    "\n",
    "for step in range(steps):\n",
    "    batch_x, batch_y = next(train_iterator)\n",
    "    preds = model.batch_predict(x=batch_x)\n",
    "    loss = model.loss_op(y_pred=preds, y_true=batch_y)\n",
    "    \n",
    "    # Normalize loss to account for batch accumulation\n",
    "    loss = loss / accumulation_size\n",
    "    \n",
    "    loss.backward()\n",
    "    \n",
    "    if (step + 1) % accumulation_size == 0 or step == len(steps) - 1:\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eef8ee0",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Misc \n",
    "\n",
    "- Code documentation\n",
    "- Writing a proper README\n",
    "- Controlled environments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b7a733",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Code documentation\n",
    "\n",
    "We have talked about type annotations and other recommendations for code readability.\n",
    "\n",
    "However, we still miss a way to understand HOW to use such code\n",
    "\n",
    "$\\rightarrow$ code documentation (a.k.a. docstrings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4857b232",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def my_function(param1: int, param2: str):\n",
    "    \"\"\"\n",
    "        This function takes ..., computes ... and then returns ...\n",
    "        \n",
    "        Args:\n",
    "            :param param1: *Description of param1*\n",
    "            :param param2: *Description of param2*\n",
    "        \n",
    "        Returns:\n",
    "            Description of return value\n",
    "    \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea5a9496",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Different docstring styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bca927ef",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "# Numpy docstring style\n",
    "def my_function(param1: int, param2: str):\n",
    "    \"\"\"\n",
    "        This function takes ..., computes ... and then returns ...\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        param1 : Description of param1\n",
    "        param2 : Description of param2\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        int\n",
    "            Description of return value\n",
    "    \"\"\"\n",
    "        ..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5668f5b",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Tools for automatic web documentation\n",
    "\n",
    "There exist several tools that can automatically parse documented code to build a documentation website of your project\n",
    "\n",
    "Among the many, [```Sphinx```](https://www.sphinx-doc.org/en/master/) is one of the most used for Python\n",
    "\n",
    "$\\rightarrow$ If you are building small libraries, then you must build the corresponding web documentation for ease use!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ac401",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Writing a proper README\n",
    "\n",
    "During research, we often define a code repository for storing our experiments.\n",
    "\n",
    "In case of paper acceptance, the code repository should be made publicly available and linked in the publication.\n",
    "\n",
    "#### What you should do?\n",
    "\n",
    "- Write a proper README file to guide users through your code repository\n",
    "\n",
    "However, in many cases, ```README``` files are partially informative, outdated, and sometimes useless."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e780a970",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### A recommended README template for research"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7818b511",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "1. Project title\n",
    "\n",
    "2. Authors\n",
    "\n",
    "3. Link to publication (if available)\n",
    "\n",
    "4. Abstract/Project description\n",
    "\n",
    "5. Repository Overview\n",
    "\n",
    "6. Instructions to perform experiments\n",
    "      1. Prerequisites\n",
    "      2. Scripts\n",
    "    \n",
    "7. FAQ\n",
    "\n",
    "8. Contributors\n",
    "\n",
    "9. How to cite\n",
    "\n",
    "10. [Optional] Disclaimer\n",
    "\n",
    "11. [Optional] License "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e15a91",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "If your project has multiple subfolders/sub-projects, make sure to include a dedicated README!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8b8a33",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Concluding Remarks\n",
    "\n",
    "1. Catching bugs requires a lot of effort! Luckily, we have many weapons\n",
    "2. Many best practices for debugging and code organization also greatly increase readability!\n",
    "3. There are several tips concerning code organization and structure that we should depending on our scenario\n",
    "4. Tensorflow and Pytorch mainly share the same type of common mistakes and best practices\n",
    "5. There are many more, often problem specific and very hard to generalize $\\rightarrow$ see 1."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470be101",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "#  (Jikai!)\n",
    "\n",
    "Actually, there's nothing left to show you... (or, better, there is still way too much stuff to talk about!)\n",
    "\n",
    "Since I wanted to hold a 10-hours course (thus, 2 CFUs), I thought it could have been a good opportunity to show you something I've been working on.\n",
    "\n",
    "- ```deasy-learning``` (*a tiny tiny custom library for research*)\n",
    "- Course feedback (*don't forget to leave a like and hit subscribe!* ~semicit)\n",
    "- **Motivational outro** (*please, don't miss this!*)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3256c3b",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Any questions?\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "<img src=\"Images/Lecture-1/jojo-arrivederci.gif\" width=\"1200\" alt='JOJO_arrivederci'/>\n",
    "</div>\n",
    "</center>"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
